{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/beir/datasets/data_loader.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "from matryoshka import Matryoshka\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc33e09f98c4eba8c66600cc3300a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/nfcorpus\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"train\")\n",
    "\n",
    "length = None\n",
    "corpus = {k: v for k, v in list(corpus.items())[:length]}\n",
    "queries = {k: v for k, v in list(queries.items())[:length]}\n",
    "qrels = {k: v for k, v in list(qrels.items())[:length]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model = Matryoshka(matryoshka_dim=384, adaptor=False)\n",
    "model = Matryoshka(matryoshka_dim=384, adaptor=True)\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "sentences = [\"sentence\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check on shape\n",
    "model(pooling=False, **inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptor.down_project.weight\n",
      "adaptor.down_project.bias\n",
      "adaptor.ffn.0.weight\n",
      "adaptor.ffn.0.bias\n",
      "adaptor.ffn.2.weight\n",
      "adaptor.ffn.2.bias\n",
      "adaptor.up_project.weight\n",
      "adaptor.up_project.bias\n"
     ]
    }
   ],
   "source": [
    "# sanity check on learble parameters\n",
    "for i in model.named_parameters():\n",
    "    if i[1][1].requires_grad:\n",
    "        print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying to reproduce original embeddings with adaptor on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [c[\"text\"] for c in corpus.values()]\n",
    "qs = list(queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlaz4rz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/matryoshka/wandb/run-20240826_151036-tqvl9twz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/laz4rz/matryoshka/runs/tqvl9twz' target=\"_blank\">identity_MSE_pooling_adapter</a></strong> to <a href='https://wandb.ai/laz4rz/matryoshka' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/laz4rz/matryoshka' target=\"_blank\">https://wandb.ai/laz4rz/matryoshka</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/laz4rz/matryoshka/runs/tqvl9twz' target=\"_blank\">https://wandb.ai/laz4rz/matryoshka/runs/tqvl9twz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.005053099431097508\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.005006635328754783\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.004983232775703073\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.004969768784940242\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.004957592720165849\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.004912418080493808\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.004866496985778212\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 0 loss: 0.004956041892095433 eval_loss: 0.004850901491743953\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0048340227454900745\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.004804914770647884\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.004781795339658857\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.004751704540103674\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.004723534733057022\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.0047036503907293085\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.004672437068074941\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 1 loss: 0.004740611081580063 eval_loss: 0.004632532032892892\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.004610352031886577\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.004582262225449085\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.00456975307315588\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.004536716407164932\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.004492115834727884\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.004450557567179203\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.0044274275656789545\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 2 loss: 0.004511817691049406 eval_loss: 0.004395039678600274\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.004382859077304601\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.004342369269579649\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.004326544050127268\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.004271081462502479\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.004244111152365804\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.004213939094915986\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.004159943154081702\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 3 loss: 0.004263326622448958 eval_loss: 0.00414035640853016\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0040905085857957605\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.0040960618760436775\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.00404063630849123\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.004016116843558848\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.004007454961538315\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.003952547977678478\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.0039203882217407225\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 4 loss: 0.004003278911113739 eval_loss: 0.003881876773544048\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0038619625847786665\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.0038038451690226792\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.0037605832796543835\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.003767887153662741\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.00371245879214257\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.003720449307002127\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.0036990393884479998\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 5 loss: 0.003753372903477836 eval_loss: 0.003641745872109344\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0036269119475036858\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.0035983032081276177\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.0035316686611622573\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.003499796148389578\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.0035133630968630313\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.003515865094959736\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.003493007062934339\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 6 loss: 0.0035288270605220036 eval_loss: 0.0034389582364574857\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0033839059993624686\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.003401350183412433\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.003324004984460771\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.003367604361847043\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.0033196110278368\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.0033420562045648693\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.003292663162574172\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 7 loss: 0.003346209190543983 eval_loss: 0.0032742680663144902\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.003247633809223771\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.0032176723470911384\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.0031631084391847255\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.0032716208137571813\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.0031856786692515014\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.003151653567329049\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.0031606014585122467\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 8 loss: 0.003199927185287143 eval_loss: 0.0031432123413603556\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0031310833524912595\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 0.003132048319093883\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 0.0030774154234677552\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 0.0030581546016037464\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 0.0030902006197720765\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 0.003054234432056546\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 0.0030792127829045056\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "Epoch: 9 loss: 0.0030836983849959715 eval_loss: 0.0030359446659292046\n",
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 0.0030112168518826366\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    base_model = base_model.cuda()\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "running_loss_step = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "similarity_loss = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "data = qs + cs\n",
    "random.shuffle(data)\n",
    "train_data = data[:int(len(data) * 0.8)]\n",
    "test_data = data[int(len(data) * 0.8):]\n",
    "\n",
    "wandb.init(\n",
    "    project=\"matryoshka\",  \n",
    "    name=\"identity_MSE_pooling_adapter\",        \n",
    "    config={                      \n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"loss\": \"MSE\",\n",
    "        \"model\": model.name,\n",
    "        \"model_card\": model.model_card_data,\n",
    "        \"loss_resolution\": running_loss_step,\n",
    "        \"architecture\": model.__str__(),\n",
    "    }\n",
    ")\n",
    "\n",
    "ls = []\n",
    "for i in range(25):\n",
    "    epoch_loss = []\n",
    "    running_loss = []\n",
    "\n",
    "    model.train()\n",
    "    random.shuffle(train_data)\n",
    "    for j in range(0, len(train_data), batch_size):\n",
    "        print(j)\n",
    "        if j + batch_size > len(train_data):\n",
    "            break\n",
    "        # c = cs[j : j + 32]\n",
    "        # q = qs[j : j + 32]\n",
    "        q = train_data[j : j + batch_size]\n",
    "\n",
    "        inputs = tokenizer(q, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        if torch.cuda.is_available():\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.cuda()\n",
    "        outputs = model(pooling=True, skip=False, **inputs)\n",
    "        target_outputs = base_model(pooling=True, **inputs)\n",
    "        loss = torch.nn.MSELoss()(outputs, target_outputs)\n",
    "        # similarity_loss = similarity_loss(outputs, target_outputs, torch.ones(len(q)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        running_loss.append(loss.item())\n",
    "        if len(running_loss) % 10 == 0:\n",
    "            print(\"Batch:\", j, \"loss:\", np.mean(running_loss))\n",
    "            wandb.log({\"batch\": j, \"loss\": np.mean(running_loss)})\n",
    "            running_loss = []\n",
    " \n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    for j in range(0, len(test_data), batch_size):\n",
    "        if j + batch_size > len(test_data):\n",
    "            break\n",
    "        q = test_data[j : j + batch_size]\n",
    "\n",
    "        inputs = tokenizer(q, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        if torch.cuda.is_available():\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pooling=True, skip=False, **inputs)\n",
    "            target_outputs = base_model(pooling=True, **inputs)\n",
    "            loss = torch.nn.MSELoss()(outputs, target_outputs)\n",
    "            eval_loss.append(loss.item())\n",
    "\n",
    "    wandb.log({\"epoch\": i, \"epoch_loss\": np.mean(epoch_loss), \"eval_loss\": np.mean(eval_loss)})\n",
    "    print(\"Epoch:\", i, \"loss:\", np.mean(epoch_loss), \"eval_loss:\", np.mean(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(11):\n",
    "    for j in range(i, 11):\n",
    "        s += 1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
